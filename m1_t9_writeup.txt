M1 Part 2: T9

	After deriving an trigram model for the T9 decoder, the major problem was producing a sufficiently large data set to facilitate a reliable rate of decoding.  Using the ngramfst documentation’s ‘toy’ data set of “The Importance of Being Earnest,” a rudimentary n-gram FST was generated that could decode T9 strings and maintain ‘reasonable’ accuracy.  (E.g. the T9 encoded phrase “hello my friends” would be produced as “iello my driends.”)  While obviously not perfect, the original phrase could be derived given contextual clues.
	Provided a 1000 line dataset from the m0 corpus, results improved such that the above phrase could be rendered as “hello my driends”.  However, punctuation remained rather random.  For instance, the punctuated version of the above phrase “hello, my friends!” would create character inaccuracies such as “helln!, my driends-”.  This seemed rather peculiar, as the original punctuation would theoretically have a greater probability count in a dataset.  As such, the dataset was extended to 100000 datapoints and an n-gram count for word tokens was developed in order to attempt a dual decoding of both character probability and word probability. 
	The addition of the word n-gram resulted in greater inaccuracy.  However, it was effective in recognizing word phrases that would have been ignored by the character model.  For example, the previous example became “iello-, nx friends!” demonstrating a final ability to recognize the final word in spite of the character model’s discrimination against /f/ onsets. 
	Attempting a compromise, I decided to expand the character model to a 6-gram, reasoning that, in practice, the character weights would approximate word probabilities due to the average length of an English word being five letters.  Thus, ideally, the character model would be better adapted to accommodate whole words and spaces.  This model paid off in nearly complete recovery of phrases from the encoding.  However, the model seems to suffer with punctuation marks outside of conventional periods and intraword apostrophes.  Given the little semantic importance such marks provide in comparison to other characters and the likely high cost in designing a comprehensive word n-gram to accommodate them, I decided to deem the current outcomes satisfactory.  
    
